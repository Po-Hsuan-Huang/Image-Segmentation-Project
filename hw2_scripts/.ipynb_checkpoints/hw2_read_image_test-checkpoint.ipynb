{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from absl import flags, app\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from glob import glob as glob\n",
    "from FCN import fcn_model\n",
    "import tensorflow as tf\n",
    "  \n",
    "data_dir = '/home/pohsuanh/Documents/Lectures/CSCI699/hw2/hw2_data'\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_data_readers(image_ids_file, get_labels=False,\n",
    "                              x_jpg_dir=None, y_png_dir=None):\n",
    "  \"\"\"Given image IDs file, returns Datasets, which generate image paths.\n",
    "\n",
    "  The goal of this function is to convert from image IDs to image paths.\n",
    "  Specifically, the return type should be:\n",
    "    if get_labels == False, return type should be tf.data.Dataset.\n",
    "    Otherwise, return type should be pair (tf.data.Dataset, tf.data.Dataset).\n",
    "  In both cases, the Dataset objects should be \"not batched\".\n",
    "\n",
    "  For example, if the file contains 2 lines: \"0000\\n0001\", then the returned\n",
    "  dataset should give an iterator that when its tensor is ran, gives \"0000\" the\n",
    "  first time and gives \"0001\" the second time.\n",
    "\n",
    "  Args:\n",
    "    image_ids_file: text with one image ID per line.\n",
    "    get_labels: If set, returns 2 Datasets: the containing the image files (x)\n",
    "      and the second containing the segmentation labels (y). If not, returns\n",
    "      only the first argument.\n",
    "    x_jpg_dir: Directory where each image lives. Specifically, image with\n",
    "      ID \"image1\" will live on \"x_jpg_dir/image1.jpg\".\n",
    "    y_png_dir: Directory where each segmentation mask lives. Specifically,\n",
    "      image with ID \"image1\" will live on \"x_png_dir/image1.png\".\n",
    "  \n",
    "  Returns:\n",
    "    instance of tf.data.Dataset, or pair of instances (if get_labels == True).\n",
    "  \"\"\"\n",
    "  x_jpg_dir = x_jpg_dir or os.path.join(data_dir, 'images')\n",
    "  y_png_dir = y_png_dir or os.path.join(data_dir, 'tf_segmentation')\n",
    "  # TODO(student): Write code.\n",
    "  \n",
    "  with open(image_ids_file,'r') as f:\n",
    "      img_ids = f.read().splitlines() \n",
    "      \n",
    "  img_paths =[]  \n",
    "  \n",
    "  for f in img_ids : \n",
    "      \n",
    "      img_paths.append( tf.cast(os.path.join( x_jpg_dir, f + '.jpg'), dtype = tf.string))\n",
    "  \n",
    "  if get_labels == False :\n",
    "      \n",
    "      data = tf.data.Dataset.list_files(img_paths)\n",
    "      \n",
    "      return data\n",
    "  \n",
    "  elif get_labels == True :\n",
    "      \n",
    "      with open(image_ids_file,'r') as f:\n",
    "          img_ids = f.read().splitlines() \n",
    "      \n",
    "      label_paths = []\n",
    "      \n",
    "      for f in img_ids : \n",
    "          label_paths.append( tf.cast( os.path.join( y_png_dir, f + '.png'), dtype = tf.string))\n",
    "          \n",
    "      return (tf.data.Dataset.list_files(img_paths),tf.data.Dataset.list_files(label_paths))\n",
    "\n",
    "def decode_image_with_padding(im_file, decode_fn=tf.image.decode_jpeg,\n",
    "                              channels=3, pad_upto=500):\n",
    "  \"\"\"Reads an image, decodes, and pads its spatial dimensions, all in TensorFlow\n",
    "\n",
    "  Args:\n",
    "    im_file: tf.string tensor, containing path to image file.\n",
    "    decode_fn: Tensorflow function for converting\n",
    "    channels: Image channels to decode. For data (x), set to 3 channels (i.e. RGB).\n",
    "      For labels (segmentation masks), set to 1, because other 2 channels contain\n",
    "      identical information.\n",
    "    pad_upto: Number of pixels to pad to.\n",
    "\n",
    "  Returns:\n",
    "    Pair of Tensors:\n",
    "      The first must be tf.int vector with 2 entries: containing the original height\n",
    "        and width of the image.\n",
    "      The second must be a tf.int matrix with size (pad_upto, pad_upto, 3)\n",
    "        i.e. the contents of the image, with zero-padding.\n",
    "  \"\"\"\n",
    "  # TODO(student): Write code.\n",
    "  print(im_file)\n",
    "  img_tensor = decode_fn(im_file, channels = channels)\n",
    "  shape = tf.shape(img_tensor)\n",
    "  img_final = tf.image.resize_image_with_pad(img_tensor, pad_upto, pad_upto)\n",
    "  \n",
    "  return (shape, img_final)\n",
    "  \n",
    "\n",
    "\n",
    "def make_loss_mask(shapes):\n",
    "  \"\"\"Given tf.int Tensor matrix with shape [N, 2], make N 2D binary masks.\n",
    "  \n",
    "  These binary masks will be used \"to mask the loss\". Specifically, if the\n",
    "  image is shaped as (300 x 400) and therefore so its labels, we only want\n",
    "  to penalize the model for misclassifying within the image boundary (300 x 400)\n",
    "  and ignore values outside (e.g. at pixel [350, 380]).\n",
    "\n",
    "  Args:\n",
    "    shapes: tf.int Tensor with shape [N, 2]. Entry shapes[i] will be a vector:\n",
    "      [image height, image width].\n",
    "\n",
    "  Returns:\n",
    "    tf.float32 mask of shape [N, 500, 500], with mask[i, h, w] set to 1.0\n",
    "    iff shapes[i, 0] < h and shapes[i, 1] < w.\n",
    "  \"\"\"\n",
    "  # TODO(student): Write code.\n",
    "  print(tf.shape(shapes).numpy()[0])\n",
    "  masks = np.zeros([len(shapes), 500, 500])\n",
    "  \n",
    "  for i in range(len(shapes)):\n",
    "      \n",
    "      with tf.Session() as sess :\n",
    "          shape = sess.run(shapes[i])\n",
    "      h,w = shape[0], shape[1]\n",
    "      masks[i, :h, :w] = np.ones([h,w])\n",
    "      \n",
    "  return masks\n",
    "      \n",
    "\n",
    "def read_image_pair_with_padding(x_im_file, y_im_file, pad_upto=500):\n",
    "  \"\"\"Reads image pair (image & segmentation). You might find it useful.\n",
    "\n",
    "  It only works properly, if you implemented `decode_image_with_padding`. If you\n",
    "  do not find this function useful, ignore it.\n",
    "  not have to use this function, if you do not find it useful.\n",
    "  \n",
    "  Args:\n",
    "    x_im_file: Full path to jpg image to be segmented.\n",
    "    y_im_file: Full path to png image, containing ground-truth segmentation.\n",
    "    pad_upto: The padding of the images.\n",
    "\n",
    "  Returns:\n",
    "    tuple of tensors with 3 entries:\n",
    "      int tensor of 2-dimensions.\n",
    "  \"\"\"\n",
    "  shape, im_x = decode_image_with_padding(x_im_file)\n",
    "  _    , im_y = decode_image_with_padding(y_im_file, tf.image.decode_png, channels=1)\n",
    "  return shape, im_x, im_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join('/home/pohsuanh/Documents/Lectures/CSCI699/hw2/hw2_data/','img_id.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths,label_paths = get_filename_data_readers(path, get_labels= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data= tf.data.Dataset.zip((img_paths,label_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paths in img_data:\n",
    "    \n",
    "    shape, img_final = decode_image_with_padding(paths, decode_fun= tf.io.decode_jpg, channel =3)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
